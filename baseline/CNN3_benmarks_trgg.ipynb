{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c6c6c3-3150-400c-beae-7cc22a7b3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# first\n",
    "# b = torch.Tensor([[[1,2,3], [4,5,6]], [[1,6,3], [9,7,6]]])\n",
    "# print (b.shape)\n",
    "\n",
    "# print (b)\n",
    "\n",
    "# c = normalize(b, dim=2)\n",
    "\n",
    "# print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e1087-0c84-408f-8f62-4e20f452c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### label align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42843422-550e-4451-bceb-32cb67a9201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "正类： 疾病(<0.5) 0 False\n",
    "\n",
    "负类： 健康人群(>0.5) 1 False\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "a = torch.tensor([0.4791, 0.3276, 0.4216, 0.5010, 0.5999, 0.5712, 0.2843, 0.3870, 0.3538,\n",
    "        0.3936, 0.4180, 0.4626, 0.4823, 0.3987, 0.4032, 0.4724, 0.5182, 0.3562,\n",
    "        0.4056, 0.4954, 0.5857, 0.5914, 0.4393, 0.4548, 0.4764, 0.3856, 0.4595,\n",
    "        0.4386, 0.4567, 0.4145, 0.4293, 0.4282, 0.3331, 0.3347, 0.4714, 0.4566,\n",
    "        0.4068, 0.5098, 0.4457, 0.4518, 0.4451, 0.4042, 0.4178, 0.3525, 0.4786,\n",
    "        0.5250, 0.5098, 0.4142, 0.5047, 0.3729, 0.4594, 0.3874, 0.4116, 0.4010,\n",
    "        0.4587, 0.3962, 0.4711, 0.4286, 0.4572, 0.4687, 0.4272, 0.4198, 0.4558,\n",
    "        0.4267])\n",
    "\n",
    "print (a)\n",
    "\n",
    "print (a.shape)\n",
    "\n",
    "flag  = a>0.5\n",
    "\n",
    "print (flag)\n",
    "\n",
    "print (True == 1)\n",
    "print (False == 0)\n",
    "\n",
    "b = torch.where(flag, 1, 0)\n",
    "\n",
    "print (b)\n",
    "\n",
    "print (b.dtype)\n",
    "\n",
    "print (1.0==1)\n",
    "\n",
    "\n",
    "ba  = b[0:5]\n",
    "\n",
    "print (ba)\n",
    "print (ba.dtype)\n",
    "\n",
    "bc = torch.tensor([.0, .0, .0, 1, 1])\n",
    "print (bc.dtype)\n",
    "print (bc)\n",
    "correct = torch.eq(ba, bc).sum().item()\n",
    "\n",
    "print (correct)\n",
    "\n",
    "# y = torch.randn(2,3,4)\n",
    "# print (y.shape)\n",
    "# y = y.transpose(0,1)\n",
    "# print (y.shape)\n",
    "\n",
    "# y = y.reshape(y.size(0),-1)\n",
    "\n",
    "# print (y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bde669-e846-41e9-83b3-2d34100a407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### max-min scaler normalization per point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0c3f2d-9c03-43be-ae51-9481003a41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin1(x):\n",
    " \n",
    "    max_value = x.max().item()\n",
    "    print ('1:', max_value)\n",
    "    min_value = x.min().item()  \n",
    "    print ('2:', min_value)\n",
    "    x_normalized = (x - min_value) / (max_value - min_value)\n",
    "     \n",
    "\n",
    "    return x_normalized\n",
    "\n",
    "# x = torch.tensor([[[1, 2], [4, 5], [7, 8]], [[3, 3], [6, 1], [9, 10]]])\n",
    "\n",
    "# print (x.shape)\n",
    "\n",
    "# x_normalized = maxmin1(x)\n",
    "\n",
    "# print (x_normalized)\n",
    "\n",
    "# x_normalized = (x - mean(x)) / std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05f190-727b-4568-aa4e-42975a03cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def maxmin2(x):\n",
    "#     full_batch = x.size(0)\n",
    "#     full_list = []\n",
    "#     for i in range(full_batch):\n",
    "#         print ('1:', x[i].shape)\n",
    "#         print ('2:', x[i])\n",
    "#         max_values, _ = x[i].max(dim=1)\n",
    "#         min_values, _ = x[i].min(dim=1)\n",
    "#         print ('3:', max_values)\n",
    "#         print ('4:', min_values)\n",
    "#         full_split = max_values.size(0)\n",
    "#         print ('5:', full_split)\n",
    "#         x_nor_split = []\n",
    "#         for j in range(full_split):\n",
    "#             print ('6:', x[i][j])\n",
    "#             x_nor_split_mini = (x[i][j] - min_values[j]) / (max_values[j] -min_values[j])\n",
    "#             x_nor_split.append(x_nor_split_mini)\n",
    "\n",
    "#         x_nor_split = torch.tensor(x_nor_split)\n",
    "#         full_list.append(x_nor_split)\n",
    "        \n",
    "#     x_normalized = torch.tensor(full_list)\n",
    "\n",
    "#     return x_normalized\n",
    "\n",
    "# x = torch.tensor([[[1, 2], [4, 5], [7, 8]], [[3, 3], [6, 1], [9, 10]]])\n",
    "\n",
    "# print (x.shape)\n",
    "\n",
    "# x_normalized = maxmin2(x)\n",
    "\n",
    "# print ('5:', x_normalized)\n",
    "# print ('6:', x_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40278f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(RG_GRFf_file_path, RG_GRFl_file_path, abn_ratio):\n",
    "\n",
    "    with open(RG_GRFf_file_path, 'rb') as file:\n",
    "        GRFf = pickle.load(file).astype(np.float32)\n",
    "    file.close()\n",
    "\n",
    "    with open(RG_GRFl_file_path, 'rb') as file:\n",
    "        GRFl = pickle.load(file).astype(np.float32)\n",
    "    file.close()\n",
    "    \n",
    "    # stat indice for 0(abnormal)/1(healthy)\n",
    "    GRFl_0_indice = np.where(GRFl==0)\n",
    "    GRFl_1_indice = np.where(GRFl==1)\n",
    "    \n",
    "    # print ('6:', GRFl_0_indice)\n",
    "    # print ('7:', GRFl_1_indice)\n",
    "    \n",
    "    # select the corresponding features for indice\n",
    "    GRFl_features_0 = GRFf[list(GRFl_0_indice[0])]\n",
    "    GRFl_features_1 = GRFf[list(GRFl_1_indice[0])]\n",
    "    \n",
    "    # select the corresponding features for indice\n",
    "    GRFl_0 = GRFl[list(GRFl_0_indice[0])]\n",
    "    GRFl_1 = GRFl[list(GRFl_1_indice[0])]\n",
    "\n",
    "    # print (GRFl_features_0.shape)\n",
    "    \n",
    "    # print (GRFl_features_1.shape)\n",
    "    \n",
    "    # 67977 abnoraml / 16574 healthy, 因此至少\n",
    "    # print (round(len(GRFl_0)/len(GRFl_1),3))\n",
    "    \n",
    "    # print (GRFl_0.shape)\n",
    "    \n",
    "    # print (GRFl_1.shape)\n",
    "\n",
    "    # 训练样本\n",
    "    #### Portation of  0(abnormal)\n",
    "    total_sample_size = GRFl_features_0.shape[0]\n",
    "    total_sample_range = list(np.arange(0, total_sample_size))\n",
    "    train_sample_size = int(GRFl_features_0.shape[0] * abn_ratio)\n",
    "    # 训练\n",
    "    train_indices = np.random.choice(GRFl_features_0.shape[0], size = train_sample_size, replace=False)\n",
    "    # print ('1:', indices)\n",
    "    # print ('2:', type(indices))\n",
    "    # print ('3:', indices.shape)\n",
    "    GRFl_features_0_portion_train = GRFl_features_0[train_indices]\n",
    "    GRFl_0_portion_train = GRFl_0[train_indices]\n",
    "    # print ('4:', GRFl_features_0_portion)\n",
    "    # print ('5:', type(GRFl_features_0_portion))\n",
    "    # print ('6:', GRFl_features_0_portion.shape)\n",
    "    # print ('44:', GRFl_0_portion)\n",
    "    # print ('7:', type(GRFl_0_portion))\n",
    "    # print ('8:', GRFl_0_portion.shape)    \n",
    "    #### Concatenate of  0(abnormal) + 1(healthy)\n",
    "    ## 3398 + 16574 = 19972\n",
    "    GRFf_train = np.concatenate((GRFl_features_0_portion_train, GRFl_features_1),axis = 0)\n",
    "    GRFl_train = np.concatenate((GRFl_0_portion_train, GRFl_1),axis = 0)\n",
    "    # print ('9:', type(GRFf)) \n",
    "    # print ('10:', GRFf.shape) \n",
    "    # print ('11:', type(GRFl)) \n",
    "    # print ('12:', GRFl.shape)\n",
    "    \n",
    "    # 测试样本\n",
    "    test_indices = []\n",
    "    for e in total_sample_range:\n",
    "        if e not in train_indices:\n",
    "            # test_indices.append(np.where(total_sample_range==e)[0][0])\n",
    "            test_indices.append(e)\n",
    "            \n",
    "    ##\n",
    "    test_indices = np.array(test_indices)\n",
    "    GRFl_features_0_portion_test = GRFl_features_0[test_indices]\n",
    "    GRFl_0_portion_test = GRFl_0[test_indices]\n",
    "    ##\n",
    "    GRFf_test = np.concatenate((GRFl_features_0_portion_test, GRFl_features_1), axis = 0)\n",
    "    GRFl_test = np.concatenate((GRFl_0_portion_test, GRFl_1), axis = 0)\n",
    "\n",
    "    ####\n",
    "    print ('13:', GRFf_train.shape)\n",
    "    print ('14:', GRFl_train.shape)\n",
    "    print ('15:', GRFf_test.shape)\n",
    "    print ('16:', GRFl_test.shape)\n",
    "\n",
    "    return GRFf_train, GRFl_train, GRFf_test, GRFl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d86a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_01(X, Y):\n",
    "    GRFf = X\n",
    "    GRFl = Y\n",
    "    # 使用SMOTE进行过采样时正样本和负样本要放在一起，生成比例1：1\n",
    "    smo = SMOTE(n_jobs=-1)\n",
    "    # 这里必须是fit_resample()，有些版本是fit_sample()无法运行\n",
    "    #### reshape, 用KNN来插值维度必须是1D\n",
    "    GRFf_1d = GRFf.reshape(GRFf.shape[0], -1)\n",
    "    # print ('test1:', GRFf.shape)\n",
    "    # 特征维度\n",
    "    GRFf_1d_fnum = GRFf.shape[1]\n",
    "    \n",
    "    # print ('1:', GRFf_1d.shape)\n",
    "    GRFf_re, GRFl_re = smo.fit_resample(GRFf_1d, GRFl)\n",
    "    \n",
    "    # print ('2:', GRFf_re.shape)\n",
    "    # print ('3:', GRFl_re.shape)\n",
    "    # 样本\n",
    "    GRFf_re = GRFf_re.reshape(GRFf_re.shape[0], GRFf_1d_fnum, -1)\n",
    "    #\n",
    "    # print ('4:', GRFf_re.shape)\n",
    "    \n",
    "    \n",
    "    #### test the distribution proportion\n",
    "    #\n",
    "    #\n",
    "    GRFl_re_0_indice = np.where(GRFl_re==0)\n",
    "    GRFl_re_1_indice = np.where(GRFl_re==1)\n",
    "    \n",
    "    #### 1:1，少数类样本0(疾病人群)数量增加为16574(0.05)\n",
    "    # print ('5:', len(list(GRFl_re_0_indice[0]))) \n",
    "    # print ('6:', len(list(GRFl_re_1_indice[0]))) \n",
    "    # print ('7:', GRFf_re)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    print ('17:', len(list(GRFl_re_0_indice[0])))\n",
    "    print ('18:', len(list(GRFl_re_1_indice[0])))    \n",
    "    \n",
    "    return GRFf_re, GRFl_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82786c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15700c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd6d2f-f48a-4b7c-9a66-362c73f9d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b37bd4-be59-4698-80f7-fe2fca81bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13: (36967, 10, 101)\n",
      "14: (36967,)\n",
      "15: (64158, 10, 101)\n",
      "16: (64158,)\n",
      "17: 20393\n",
      "18: 20393\n",
      "17: 47584\n",
      "18: 47584\n",
      "1: 1.6614514589309692\n",
      "2: -0.43713119626045227\n",
      "1: 1.6962571144104004\n",
      "2: -0.43713119626045227\n"
     ]
    }
   ],
   "source": [
    "# ---------------1、load---------------\n",
    "RG_GRFf_file_path = 'DataSet1/GRFf.pkl'\n",
    "RG_GRFl_file_path = 'DataSet1/GRFl.pkl'\n",
    "\n",
    "# part ratio，这里健康样本是陪衬，一直要加上\n",
    "abn_ratio = 0.3 # 30%训练\n",
    "# abn_ratio = 0.2 # 20%训练\n",
    "# abn_ratio = 0.1 # 10%\n",
    "# abn_ratio = 0.05 # 5%\n",
    "\n",
    "\n",
    "# 按比例切分样本，但目前是固定10%:90%, 20%:80%, 30%:70%, 但目前的10% 20% 30%必须变起来写成随机化的(sampler???)\n",
    "GRFf_train_part, GRFl_train_part, GRFf_val_part, GRFl_val_part  =  partition(RG_GRFf_file_path, RG_GRFl_file_path, abn_ratio)\n",
    "# 平衡训练集样本量，正负样本数为1:1\n",
    "GRFf_train_ba, GRFl_train_ba = balance_01(GRFf_train_part, GRFl_train_part)\n",
    "# 平衡训练集样本量，正负样本数为1:1\n",
    "GRFf_val_ba, GRFl_val_ba = balance_01(GRFf_val_part, GRFl_val_part)\n",
    "\n",
    "# ------------------------ 2、normlization max-min scaler------------------------\n",
    "GRFf_train = torch.from_numpy(GRFf_train_ba)\n",
    "GRFf_train = maxmin1(GRFf_train)\n",
    "\n",
    "GRFf_val = torch.from_numpy(GRFf_val_ba)\n",
    "GRFf_val = maxmin1(GRFf_val)\n",
    "\n",
    "#\n",
    "GRFl_train = torch.from_numpy(GRFl_train_ba)\n",
    "GRFl_val = torch.from_numpy(GRFl_val_ba)\n",
    "\n",
    "# ------------------------ 3、Tensor Dataset------------------------\n",
    "train_set = TensorDataset(GRFf_train, GRFl_train)\n",
    "val_set = TensorDataset(GRFf_val, GRFl_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0409319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11: <torch.utils.data.dataloader.DataLoader object at 0x000001B740396010>\n",
      "12: <torch.utils.data.dataloader.DataLoader object at 0x000001B73D95F690>\n",
      "13: 1275\n",
      "14: 1983\n"
     ]
    }
   ],
   "source": [
    "# -----------------4、dataloader------------------------\n",
    "\n",
    "abn_ratio = 0.01 # 1% \n",
    "val_percent = 0.3\n",
    "train_batch_size = 32\n",
    "test_batch_size = 48\n",
    "workers  = 3\n",
    "pin_memory = True\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size = train_batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = workers,\n",
    "    pin_memory = pin_memory,\n",
    "    sampler = None\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size = test_batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers = workers,\n",
    "    pin_memory = pin_memory\n",
    ")\n",
    "\n",
    "print ('11:', train_loader)\n",
    "print ('12:', val_loader)\n",
    "\n",
    "print ('13:', len(train_loader))\n",
    "print ('14:', len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69d7ac-2413-4398-89d9-7c784ed7b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5b0792-48d8-41f8-a3b2-0d3d2e5064f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积组: Conv2d+BN+ReLU\n",
    "class BasicConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(BasicConv1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = BasicConv1d(10, 128, 3)\n",
    "        self.conv2 = BasicConv1d(128, 64, 3)\n",
    "        self.conv3 = BasicConv1d(64, 32, 3)\n",
    "        self.maxp = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(32 * 94, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # print ('1:', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print ('2:', x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print ('3:', x.shape)\n",
    "        x = self.maxp(x)\n",
    "        # print ('4:', x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print ('5:', x.shape)\n",
    "        x = x.reshape(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        # print ('6:', x.shape)\n",
    "        X = self.sigmoid(x).squeeze()\n",
    "        # print ('7:', X.shape)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43b160-1d8d-4311-8b71-c48e665b1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cee7c79-a449-44e2-9aa4-afb491db593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): BasicConv1d(\n",
      "    (conv): Conv1d(10, 128, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv2): BasicConv1d(\n",
      "    (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv3): BasicConv1d(\n",
      "    (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxp): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=3008, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ConvNet().to(device)\n",
    "print (net)\n",
    "net = net.to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# 0.1 reduce / 10 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "###\n",
    "# epochs = 100\n",
    "epochs = 1\n",
    "\n",
    "# acc\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred, 1, 0)\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "# confusion matrix\n",
    "# 混淆矩阵计算\n",
    "def calculate_performance_metrics(y_true, y_pred, labels):\n",
    "\n",
    "    # 预测矩阵转换0 1矩阵\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred,1,0)\n",
    "\n",
    "    # print ('0:', y_pred)\n",
    "    # print ('00:', y_true)\n",
    "    # print ('0_:', y_pred.shape)\n",
    "    # print ('00_:', y_true.shape)\n",
    "    \n",
    "\n",
    "    # 再转换为numpy类型\n",
    "    # y_pred = y_pred.detach().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # y_true = y_true.detach().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "\n",
    "    # print ('11:', type(y_pred))\n",
    "    # print ('22:', type(y_true))\n",
    "    # print ('33:', y_pred.shape)\n",
    "    # print ('44:', y_true.shape)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # 混淆矩阵画图\n",
    "#     fx = plot_cm(cm)\n",
    "    \n",
    "    # 计算精度\n",
    "    precision = precision_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算召回率\n",
    "    recall = recall_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算F1分数\n",
    "    f1 = f1_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算平衡F1分数\n",
    "    # 这里假设有一个函数balanced_accuracy_score来计算平衡F1分数\n",
    "    balanced_f1 = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return cm, precision, recall, f1, balanced_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86850723-d9d2-496b-814a-2b666d608bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a0cd01-0238-4063-8108-c453296c3d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu:0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5999994250014424e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,\n",
    "                     end:float,\n",
    "                     device:torch.device =None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}:{total_time:.3f} seconds\")\n",
    "    return total_time\n",
    " \n",
    "start_time = timer()\n",
    "# 模型的运算在此处进行……\n",
    "end_time = timer()\n",
    "print_train_time(start = start_time,end=end_time,device=\"cpu\")\n",
    " \n",
    "# 运行结果\n",
    "# Train time on cpu:0.000 seconds\n",
    "# 3.819999983534217e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355115d-5d22-40fd-81be-1351376259f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc050c-1892-41ad-a5eb-99ab8c2719d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import *\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer() \n",
    " \n",
    "##############################################\n",
    "for epoch in tqdm(range(epochs)):  \n",
    "    print(f\"Epoch:{epoch}\\n------\")\n",
    "    train_loss = 0 \n",
    "    for batch,(X,y) in enumerate(train_loader): \n",
    "        #\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        net.train() \n",
    "        y_pred = net(X)\n",
    "        #\n",
    "        # print ('1:', y_pred)\n",
    "        # print ('2:', y_pred.shape)\n",
    "        # print ('3:', y)\n",
    "        # print ('4:', y.shape)        \n",
    " \n",
    "        loss = criterion(y_pred,y)\n",
    "        # print ('train_loss:', loss)\n",
    "        train_loss+=loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        loss.backward()\n",
    " \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    " \n",
    "        # if batch % 400 == 0:\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Look at {batch * len(X)}/{len(train_loader.dataset)} samples.\")\n",
    "            # break\n",
    " \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "\n",
    "    ###################val/per epoch###########################\n",
    "    val_loss, val_acc = 0, 0 \n",
    "    net.eval() \n",
    "    precision_t = 0\n",
    "    recall_t = 0\n",
    "    f1_t = 0\n",
    "    balanced_f1_t = 0\n",
    "    cm_t = np.zeros((2,2))\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for x_val, y_val in val_loader:\n",
    "            #\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            val_pred = net(x_val) \n",
    "            val_loss+=criterion(val_pred, y_val)\n",
    "            # print ('test_loss:', loss)\n",
    "            # print ('val_pred:', val_pred)\n",
    "            # print ('y_val:', y_val)\n",
    "            # print ('val_pred:', val_pred.shape)\n",
    "            # print ('y_val:', val_pred.shape)\n",
    "            val_acc += accuracy_fn(y_true = y_val, y_pred = val_pred)\n",
    "            cm, precision, recall, f1, balanced_f1 = calculate_performance_metrics(y_true = y_val, y_pred = val_pred, labels=[0,1])\n",
    "            \n",
    "            precision_t += precision\n",
    "            recall_t += recall\n",
    "            f1_t += f1\n",
    "            balanced_f1_t += balanced_f1\n",
    "            cm_t += cm\n",
    "            \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        precision_t /=len(val_loader)\n",
    "        recall_t /=len(val_loader)\n",
    "        f1_t /=len(val_loader)\n",
    "        balanced_f1_t /=len(val_loader)\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(f\"\\nTrain loss:{train_loss:.4f} | Test loss:{val_loss:.4f}, Test acc:{val_acc:.4f}\")\n",
    "    \n",
    "    print ('avg-precision:', precision_t)\n",
    "    print ('avg-recall:', recall_t)\n",
    "    print ('avg-f1:', f1_t)\n",
    "    print ('avg-balanced_f1:', balanced_f1_t)\n",
    "    print ('last-cm:', cm_t)\n",
    "\n",
    "\n",
    "# 计算训练时间\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(net.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87664552-ea79-4bc5-ae33-9dbe10d62d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "如图，可发现，用Seaborn画出来的热力图中，只有第一行单元格有数字，其他行单元格均不显示数字。\n",
    "\n",
    "二、找出原因\n",
    "\n",
    "首先排除了参数使用错误这一原因，因为在sns.heatmap函数中，我的annot这一参数使用的是\"True\"，即单元格中显示数值。\n",
    "\n",
    "sns.heatmap(wine_data_heat.corr() , annot = True,\n",
    "            xticklabels=x,\n",
    "            yticklabels=y)\n",
    "后面在网上找了一些资料，发现是matplotlib版本过高的原因：matplotlib一直在更新，我现在使用是的matplotlib 3.8.2，而seaborn最新版本是在2023年4月更新的。\n",
    "\n",
    "三、解决问题\n",
    "\n",
    "我尝试将matplotlib的版本降低为3.7.3。\n",
    "\n",
    "在cmd中执行命令行，查看当前版本：                      \n",
    "'''\n",
    "\n",
    "\n",
    "import seaborn as sebrn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(7)))\n",
    "# conf_matrix = [conf_matrix[i]*1.0/sum(conf_matrix[i]) for i in range(len(conf_matrix))]\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "# fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"turbo\")\n",
    "\n",
    "# # labels the title and x, y axis of plot\n",
    "# fx.set_title(\"Plotting Confusion Matrix using Seaborn\\n\\n\")\n",
    "# fx.set_xlabel(\"Predicted Values\")\n",
    "# fx.set_ylabel(\"Actual Values \")\n",
    "\n",
    "# # labels the boxes\n",
    "# fx.xaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "# fx.yaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "\n",
    "# atlas.show()\n",
    "\n",
    "#### 混淆矩阵画图\n",
    "print ('cm_total:', cm_t)\n",
    "\n",
    "print ('1:', cm_t[0])\n",
    "print ('2:', sum(cm_t[0]))\n",
    "\n",
    "conf_matrix = [cm_t[i]*1.0/sum(cm_t[i]) for i in range(len(cm_t))]\n",
    "\n",
    "# conf_matrix = cm_total\n",
    "\n",
    "print ('conf_matrix:', conf_matrix)\n",
    "fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "# fx = sebrn.heatmap(cm_t, annot=True, cmap=\"YlGnBu\")\n",
    "\n",
    "# sn.heatmap(cm_total,annot=True)\n",
    "\n",
    "fx.set_title(\"Normalized Confusion Matrix for MA²\\n\\n\")\n",
    "# fx.set_title(\"Confusion Matrix for MA²\\n\\n\")\n",
    "#\n",
    "fx.set_xlabel(\"Predicted Values\")\n",
    "fx.set_ylabel(\"True Values \")\n",
    "\n",
    "fx.xaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "fx.yaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "plt.savefig(\"MA2_con\", dpi=330)\n",
    "plt.show()\n",
    "\n",
    "plt.cla\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f29890-e866-431c-8f3e-8c282c43837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628861ab-a011-4a43-8881-a3e74ad3d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9eed5-84a6-46a6-bd18-62bd4753b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8914c30-a495-4451-8616-5b54ad406128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define LSTM Neural Networks\n",
    "class LstmRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Parameters：\n",
    "        - input_size: feature size\n",
    "        - hidden_size: number of hidden units\n",
    "        - output_size: number of output\n",
    "        - num_layers: layers of LSTM to stack\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, input_size, hidden_size=1, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    " \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)  # utilize the LSTM model in torch.nn\n",
    "        self.linear = nn.Linear(hidden_size, output_size) # 全连接层\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, _x):\n",
    "        # transpose1\n",
    "        _x = _x.transpose(0,2)  # _x is input, size (seq_len, input_size, batch)\n",
    "        _x = _x.transpose(1,2)  # _x is input, size (seq_len, batch, input_size)\n",
    "        # print ('0:', _x.shape)\n",
    "        \n",
    "        x, _ = self.lstm(_x)  # _x is input, size (seq_len, batch, input_size)\n",
    "        s, b, h = x.shape  # x is output, size (seq_len, batch, hidden_size)\n",
    "        # transpose2\n",
    "        # x = x.transpose(0,1) #  size (batch, seq_len , hidden_size)\n",
    "        # reshape\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        # print ('1:', x.shape)\n",
    "        x = self.linear(x)\n",
    "        X = x[-1, :, :]\n",
    "        # print ('2:', X.shape)        \n",
    "        X = self.sigmoid(X).squeeze()\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb99a7-8065-450e-bb8a-0fe4f566201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36775a0d-2b82-4b4b-9952-54272aab87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f2972-72cd-4023-a4ad-941620119394",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "INPUT_FEATURES_NUM = 10\n",
    "HIDDEN_FEATURES_NUM = 128\n",
    "OUTPUT_FEATURES_NUM = 1\n",
    "LAYERS_NUM = 3\n",
    "net2 = LstmRNN(input_size = INPUT_FEATURES_NUM, hidden_size = HIDDEN_FEATURES_NUM, output_size = OUTPUT_FEATURES_NUM, num_layers = LAYERS_NUM)  \n",
    "print (net2)\n",
    "net2 = net2.to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# 0.1 reduce / 10 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "###\n",
    "# epochs = 100\n",
    "epochs = 1\n",
    "\n",
    "# acc\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred, 1, 0)\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "# 混淆矩阵计算\n",
    "def calculate_performance_metrics(y_true, y_pred, labels):\n",
    "\n",
    "    # 预测矩阵转换0 1矩阵\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred,1,0)\n",
    "\n",
    "    # print ('0:', y_pred)\n",
    "    # print ('00:', y_true)\n",
    "    # print ('0_:', y_pred.shape)\n",
    "    # print ('00_:', y_true.shape)\n",
    "    \n",
    "\n",
    "    # 再转换为numpy类型\n",
    "    # y_pred = y_pred.detach().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # y_true = y_true.detach().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "\n",
    "    # print ('11:', type(y_pred))\n",
    "    # print ('22:', type(y_true))\n",
    "    # print ('33:', y_pred.shape)\n",
    "    # print ('44:', y_true.shape)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # 混淆矩阵画图\n",
    "#     fx = plot_cm(cm)\n",
    "    \n",
    "    # 计算精度\n",
    "    precision = precision_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算召回率\n",
    "    recall = recall_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算F1分数\n",
    "    f1 = f1_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算平衡F1分数\n",
    "    # 这里假设有一个函数balanced_accuracy_score来计算平衡F1分数\n",
    "    balanced_f1 = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return cm, precision, recall, f1, balanced_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685db39d-62bf-43c5-a16a-a000f68d48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495c84b-0287-4fda-b472-11395a7bf7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import *\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer() \n",
    " \n",
    " \n",
    "##############################################\n",
    "for epoch in tqdm(range(epochs)):  \n",
    "    print(f\"Epoch:{epoch}\\n------\")\n",
    "    train_loss = 0 \n",
    "    for batch,(X,y) in enumerate(train_loader): \n",
    "        #\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        net2.train() \n",
    "        y_pred = net2(X)\n",
    "        #\n",
    "        # print ('1:', y_pred)\n",
    "        # print ('2:', y_pred.shape)\n",
    "        # print ('3:', y)\n",
    "        # print ('4:', y.shape)        \n",
    " \n",
    "        loss = criterion(y_pred,y)\n",
    "        # print ('train_loss:', loss)\n",
    "        train_loss+=loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        loss.backward()\n",
    " \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    " \n",
    "        # if batch % 400 == 0:\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Look at {batch * len(X)}/{len(train_loader.dataset)} samples.\")\n",
    "            # break\n",
    " \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "\n",
    "    \n",
    "###################val/per epoch###########################\n",
    "    val_loss, val_acc = 0, 0\n",
    "    precision_t = 0\n",
    "    recall_t = 0\n",
    "    f1_t = 0\n",
    "    balanced_f1_t = 0\n",
    "    cm_t = np.zeros((2,2))    \n",
    "    net2.eval() \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for x_val, y_val in val_loader:\n",
    "            #\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            val_pred = net2(x_val) \n",
    "            val_loss+=criterion(val_pred, y_val)\n",
    "            # print ('test_loss:', loss)\n",
    "            # print ('val_pred:', val_pred)\n",
    "            # print ('y_val:', y_val)\n",
    "            # print ('val_pred:', val_pred.shape)\n",
    "            # print ('y_val:', val_pred.shape)\n",
    "            val_acc += accuracy_fn(y_true = y_val, y_pred = val_pred)\n",
    "            cm, precision, recall, f1, balanced_f1 = calculate_performance_metrics(y_true = y_val, y_pred = val_pred, labels=[0,1])  \n",
    "\n",
    "            precision_t += precision\n",
    "            recall_t += recall\n",
    "            f1_t += f1\n",
    "            balanced_f1_t += balanced_f1\n",
    "            cm_t += cm\n",
    "\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        precision_t /=len(val_loader)\n",
    "        recall_t /=len(val_loader)\n",
    "        f1_t /=len(val_loader)\n",
    "        balanced_f1_t /=len(val_loader)\n",
    "\n",
    "    \n",
    "    print(f\"\\nTrain loss:{train_loss:.4f} | Test loss:{val_loss:.4f}, Test acc:{val_acc:.4f}\")\n",
    "    \n",
    "    print ('avg-precision:', precision_t)\n",
    "    print ('avg-recall:', recall_t)\n",
    "    print ('avg-f1:', f1_t)\n",
    "    print ('avg-balanced_f1:', balanced_f1_t)\n",
    "    print ('last-cm:', cm_t)\n",
    "    \n",
    " # 计算训练时间\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(net2.parameters()).device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b487c2-9d49-4f4d-8fec-a1feab043e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sebrn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(7)))\n",
    "# conf_matrix = [conf_matrix[i]*1.0/sum(conf_matrix[i]) for i in range(len(conf_matrix))]\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "# fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"turbo\")\n",
    "\n",
    "# # labels the title and x, y axis of plot\n",
    "# fx.set_title(\"Plotting Confusion Matrix using Seaborn\\n\\n\")\n",
    "# fx.set_xlabel(\"Predicted Values\")\n",
    "# fx.set_ylabel(\"Actual Values \")\n",
    "\n",
    "# # labels the boxes\n",
    "# fx.xaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "# fx.yaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "\n",
    "# atlas.show()\n",
    "\n",
    "#### 混淆矩阵画图\n",
    "print ('cm_total:', cm_t)\n",
    "\n",
    "print ('1:', cm_t[0])\n",
    "print ('2:', sum(cm_t[0]))\n",
    "\n",
    "conf_matrix = [cm_t[i]*1.0/sum(cm_t[i]) for i in range(len(cm_t))]\n",
    "\n",
    "# conf_matrix = cm_total\n",
    "\n",
    "print ('conf_matrix:', conf_matrix)\n",
    "fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "# fx = sebrn.heatmap(cm_t, annot=True, cmap=\"YlGnBu\")\n",
    "\n",
    "# sn.heatmap(cm_total,annot=True)\n",
    "\n",
    "fx.set_title(\"Normalized Confusion Matrix for MA²\\n\\n\")\n",
    "# fx.set_title(\"Confusion Matrix for MA²\\n\\n\")\n",
    "#\n",
    "fx.set_xlabel(\"Predicted Values\")\n",
    "fx.set_ylabel(\"True Values \")\n",
    "\n",
    "fx.xaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "fx.yaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "plt.savefig(\"MA2_con\", dpi=330)\n",
    "plt.show()\n",
    "\n",
    "plt.cla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93248bb5-c47a-4c79-8d66-67485e56d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa170c5-78a2-4c12-81e3-a81d888c30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0866a53-8d88-4f2c-8868-7f66e1f2c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac8ae9-48ac-49c1-9610-152abb069131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1DCNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d68fb3ab-ad3a-4355-81dc-923c43f942fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(BasicConv1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class CNN3LSTM(nn.Module):\n",
    "    def __init__(self, lstm_input_size, lstm_hidden_size=1, lstm_output_size=1, lstm_num_layers=1):\n",
    "        super(CNN3LSTM, self).__init__()\n",
    "        self.conv1 = BasicConv1d(10, 512, 1)\n",
    "        self.conv2 = BasicConv1d(512, 256, 1)\n",
    "        self.conv3 = BasicConv1d(256, 64, 1)\n",
    "        self.conv4 = BasicConv1d(64, 256, 3)\n",
    "        self.conv5 = BasicConv1d(256, 512, 3)\n",
    "        self.conv6 = BasicConv1d(512, 256, 3)\n",
    "       \n",
    "        self.maxp = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        # Diu1\n",
    "        # self.dropout = nn.Dropout(0.5)\n",
    "        ## Diu2\n",
    "        self.lstm = nn.LSTM(256, lstm_hidden_size, lstm_hidden_size)  # utilize the LSTM model in torch.nn\n",
    "        self.linear = nn.Linear(lstm_hidden_size, lstm_output_size) # 全连接层\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        \n",
    "        # x = self.maxp(x)\n",
    "        # _x = self.dropout(x)\n",
    "        _x = self.maxp(x)\n",
    "\n",
    "        # LSTM\n",
    "        # transpose1\n",
    "        _x = _x.transpose(0,2)  # _x is input, size (seq_len, input_size, batch)\n",
    "        _x = _x.transpose(1,2)  # _x is input, size (seq_len, batch, input_size)\n",
    "        # print ('0:', _x.shape)\n",
    "        \n",
    "        x_, _ = self.lstm(_x)  # _x is input, size (seq_len, batch, input_size)\n",
    "        s, b, h = x_.shape  # x is output, size (seq_len, batch, hidden_size)        \n",
    "        x_ = self.linear(x_)\n",
    "        X = x_[-1, :, :]\n",
    "        # print ('2:', X.shape)        \n",
    "        X = self.sigmoid(X).squeeze()\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce250df9-ab98-4680-9f2c-98af5471e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0ff6c5f-c343-4de2-9475-91805b090f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN3LSTM(\n",
      "  (conv1): BasicConv1d(\n",
      "    (conv): Conv1d(10, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv2): BasicConv1d(\n",
      "    (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv3): BasicConv1d(\n",
      "    (conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv4): BasicConv1d(\n",
      "    (conv): Conv1d(64, 256, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv5): BasicConv1d(\n",
      "    (conv): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv6): BasicConv1d(\n",
      "    (conv): Conv1d(512, 256, kernel_size=(3,), stride=(1,))\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxp): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm): LSTM(256, 128, num_layers=128)\n",
      "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "INPUT_FEATURES_NUM = 10\n",
    "HIDDEN_FEATURES_NUM = 128\n",
    "OUTPUT_FEATURES_NUM = 1\n",
    "LAYERS_NUM = 3\n",
    "net3 = CNN3LSTM(lstm_input_size = INPUT_FEATURES_NUM, lstm_hidden_size = HIDDEN_FEATURES_NUM, lstm_output_size = OUTPUT_FEATURES_NUM, lstm_num_layers = LAYERS_NUM)  \n",
    "print (net3)\n",
    "net3 = net3.to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.0001)\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.001)\n",
    "#\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.00001)\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.000001)\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.0001)\n",
    "optimizer = optim.AdamW(net3.parameters())\n",
    "\n",
    "# optimizer = optim.Adam(net3.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# 0.1 reduce / 10 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "###\n",
    "# epochs = 100\n",
    "epochs = 3\n",
    "\n",
    "# acc\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred, 1, 0)\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "# 混淆矩阵计算\n",
    "def calculate_performance_metrics(y_true, y_pred, labels):\n",
    "\n",
    "    # 预测矩阵转换0 1矩阵\n",
    "    y_pred = y_pred>0.5\n",
    "    y_pred = torch.where(y_pred,1,0)\n",
    "\n",
    "    # print ('0:', y_pred)\n",
    "    # print ('00:', y_true)\n",
    "    # print ('0_:', y_pred.shape)\n",
    "    # print ('00_:', y_true.shape)\n",
    "    \n",
    "\n",
    "    # 再转换为numpy类型\n",
    "    # y_pred = y_pred.detach().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # y_true = y_true.detach().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "\n",
    "    # print ('11:', type(y_pred))\n",
    "    # print ('22:', type(y_true))\n",
    "    # print ('33:', y_pred.shape)\n",
    "    # print ('44:', y_true.shape)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # 混淆矩阵画图\n",
    "#     fx = plot_cm(cm)\n",
    "    \n",
    "    # 计算精度\n",
    "    precision = precision_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算召回率\n",
    "    recall = recall_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算F1分数\n",
    "    f1 = f1_score(y_true, y_pred, labels = labels, average = 'macro')\n",
    "    \n",
    "    # 计算平衡F1分数\n",
    "    # 这里假设有一个函数balanced_accuracy_score来计算平衡F1分数\n",
    "    balanced_f1 = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return cm, precision, recall, f1, balanced_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8de79cd-67ec-4ced-8836-be37a0df5a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu:0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.509998739697039e-05"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,\n",
    "                     end:float,\n",
    "                     device:torch.device =None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}:{total_time:.3f} seconds\")\n",
    "    return total_time\n",
    " \n",
    "start_time = timer()\n",
    "# 模型的运算在此处进行……\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time,end=end_time,device=\"cpu\")\n",
    " \n",
    "# 运行结果\n",
    "# Train time on cpu:0.000 seconds\n",
    "# 3.819999983534217e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f210a7-d4e1-4887-90c7-8fd1b9d7b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3802ea8-b383-4fa2-b7f1-d38d8e2b695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "------\n",
      "Look at 0/40786 samples.\n",
      "Look at 12800/40786 samples.\n",
      "Look at 25600/40786 samples.\n",
      "Look at 38400/40786 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▋                                                       | 1/3 [02:52<05:45, 172.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss:0.6932 | Test loss:0.6932, Test acc:50.0084\n",
      "avg-precision: 0.2500420238695579\n",
      "avg-recall: 0.25012607160867373\n",
      "avg-f1: 0.25007564296520424\n",
      "avg-balanced_f1: 0.5\n",
      "last-cm: [[47552. 95136.]\n",
      " [47552. 47584.]]\n",
      "Epoch:1\n",
      "------\n",
      "Look at 0/40786 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▋                                                       | 1/3 [03:02<06:05, 182.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch,(X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader): \n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     net3\u001b[38;5;241m.\u001b[39mtrain() \n\u001b[0;32m     14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m net3(X)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import *\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer() \n",
    " \n",
    "##############################################\n",
    "for epoch in tqdm(range(epochs)):  \n",
    "    print(f\"Epoch:{epoch}\\n------\")\n",
    "    train_loss = 0 \n",
    "    for batch,(X,y) in enumerate(train_loader): \n",
    "        #\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        net3.train() \n",
    "        y_pred = net3(X)\n",
    "        #\n",
    "        # print ('1:', y_pred)\n",
    "        # print ('2:', y_pred.shape)\n",
    "        # print ('3:', y)\n",
    "        # print ('4:', y.shape)        \n",
    " \n",
    "        loss = criterion(y_pred,y)\n",
    "        # print ('train_loss:', loss)\n",
    "        train_loss+=loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        loss.backward()\n",
    " \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    " \n",
    "        # if batch % 400 == 0:\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Look at {batch * len(X)}/{len(train_loader.dataset)} samples.\")\n",
    "            # break\n",
    " \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    " \n",
    "###################val/per epoch###########################\n",
    "    val_loss, val_acc = 0, 0 \n",
    "    precision_t = 0\n",
    "    recall_t = 0\n",
    "    f1_t = 0\n",
    "    balanced_f1_t = 0\n",
    "    cm_t = np.zeros((2,2))\n",
    "    net3.eval() \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for x_val, y_val in val_loader:\n",
    "            #\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            val_pred = net3(x_val) \n",
    "            val_loss+=criterion(val_pred, y_val)\n",
    "            # print ('test_loss:', loss)\n",
    "            # print ('val_pred:', val_pred)\n",
    "            # print ('y_val:', y_val)\n",
    "            # print ('val_pred:', val_pred.shape)\n",
    "            # print ('y_val:', val_pred.shape)\n",
    "            val_acc += accuracy_fn(y_true = y_val, y_pred = val_pred)\n",
    "            cm, precision, recall, f1, balanced_f1 = calculate_performance_metrics(y_true = y_val, y_pred = val_pred, labels=[0,1])\n",
    "\n",
    "            precision_t += precision\n",
    "            recall_t += recall\n",
    "            f1_t += f1\n",
    "            balanced_f1_t += balanced_f1\n",
    "            cm_t += cm\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        #\n",
    "        precision_t /=len(val_loader)\n",
    "        recall_t /=len(val_loader)\n",
    "        f1_t /=len(val_loader)\n",
    "        balanced_f1_t /=len(val_loader)\n",
    "        \n",
    "    print(f\"\\nTrain loss:{train_loss:.4f} | Test loss:{val_loss:.4f}, Test acc:{val_acc:.4f}\")\n",
    "    print ('avg-precision:', precision_t)\n",
    "    print ('avg-recall:', recall_t)\n",
    "    print ('avg-f1:', f1_t)\n",
    "    print ('avg-balanced_f1:', balanced_f1_t)\n",
    "    print ('last-cm:', cm_t)\n",
    "    \n",
    "# 计算训练时间\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(net3.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80928065-12ac-45bf-9ba5-c3e0afd06137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37895af-774c-4384-ada0-973f09991ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sebrn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(7)))\n",
    "# conf_matrix = [conf_matrix[i]*1.0/sum(conf_matrix[i]) for i in range(len(conf_matrix))]\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "# fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"turbo\")\n",
    "\n",
    "# # labels the title and x, y axis of plot\n",
    "# fx.set_title(\"Plotting Confusion Matrix using Seaborn\\n\\n\")\n",
    "# fx.set_xlabel(\"Predicted Values\")\n",
    "# fx.set_ylabel(\"Actual Values \")\n",
    "\n",
    "# # labels the boxes\n",
    "# fx.xaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "# fx.yaxis.set_ticklabels(['suprised', 'afraid', 'disgust', 'happy', 'sad', 'angry', 'neutral'])\n",
    "\n",
    "# atlas.show()\n",
    "\n",
    "#### 混淆矩阵画图\n",
    "print ('cm_total:', cm_t)\n",
    "\n",
    "print ('1:', cm_t[0])\n",
    "print ('2:', sum(cm_t[0]))\n",
    "\n",
    "conf_matrix = [cm_t[i]*1.0/sum(cm_t[i]) for i in range(len(cm_t))]\n",
    "\n",
    "# conf_matrix = cm_total\n",
    "\n",
    "print ('conf_matrix:', conf_matrix)\n",
    "fx = sebrn.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "# fx = sebrn.heatmap(cm_t, annot=True, cmap=\"YlGnBu\")\n",
    "\n",
    "# sn.heatmap(cm_total,annot=True)\n",
    "\n",
    "fx.set_title(\"Normalized Confusion Matrix for MA²\\n\\n\")\n",
    "# fx.set_title(\"Confusion Matrix for MA²\\n\\n\")\n",
    "#\n",
    "fx.set_xlabel(\"Predicted Values\")\n",
    "fx.set_ylabel(\"True Values \")\n",
    "\n",
    "fx.xaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "fx.yaxis.set_ticklabels(['pathologic', 'healthy',])\n",
    "plt.savefig(\"MA2_con\", dpi=330)\n",
    "plt.show()\n",
    "\n",
    "plt.cla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4971df-5016-426a-a23c-8049aabc4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc50e0-5309-47df-9a04-03ccc1a3e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da07919-854e-4e51-b014-3361e59cf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01705e-ea6f-48c7-aa8f-7df2e8882553",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db44ae-91cf-4910-92e5-5a023943ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (0==False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
